{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2046e9",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddac63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Required pacakges\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "from scipy.stats import norm\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.optimizers as opt\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0dabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions from paper\n",
    "'''\n",
    "\n",
    "def generate_covariance_from_correlation(cor_mat, vol_list, dt):\n",
    "    vol_diag_mat = np.diag(vol_list)\n",
    "    cov_mat = np.dot(np.dot(vol_diag_mat, cor_mat), vol_diag_mat) * dt\n",
    "    return cov_mat\n",
    "\n",
    "\n",
    "def multi_variate_gbm_simulation(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets,\n",
    "                                 curr_stock_price, r, vol_list, cov_mat, t):\n",
    "    zero_mean = np.zeros(no_of_assets)\n",
    "\n",
    "    dw_mat = np.random.multivariate_normal(zero_mean, cov_mat, (no_of_paths, no_of_exercise_days))\n",
    "    dt = t / no_of_exercise_days\n",
    "\n",
    "    sim_ln_stock_mat = np.zeros((no_of_paths, no_of_exercise_days + 1, no_of_assets))\n",
    "    sim_ln_stock_mat[:, 0] = np.tile(np.log(curr_stock_price), (no_of_paths, 1))\n",
    "    base_drift = np.tile((np.add(np.full(no_of_assets, r), - 0.5 * np.square(vol_list))), (no_of_paths, 1)) * dt\n",
    "\n",
    "    for day in range(1, no_of_exercise_days + 1):\n",
    "        curr_drift = sim_ln_stock_mat[:, day - 1] + base_drift\n",
    "        sim_ln_stock_mat[:, day] = curr_drift + dw_mat[:, day - 1]\n",
    "\n",
    "    sim_stock_mat = np.exp(sim_ln_stock_mat)\n",
    "    return sim_stock_mat\n",
    "\n",
    "\n",
    "def duplicates(lst, item):\n",
    "    return [i for i, x in enumerate(lst) if x == item]\n",
    "\n",
    "\n",
    "def pricer_arithmetic_pre(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets, w, sim_stock_mat,\n",
    "                          batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, model):\n",
    "\n",
    "    continuation_value = np.zeros((no_of_paths, 1))\n",
    "    stock_vec = sim_stock_mat[:, no_of_exercise_days]\n",
    "    intrinsic_value = np.maximum(k - np.dot(stock_vec, w), 0)\n",
    "    continuation_value = intrinsic_value\n",
    "    \n",
    "    # Finding intrinsic value of the option for all paths and exercise days\n",
    "    for day in range(no_of_exercise_days - 1, no_of_exercise_days - 2, -1):\n",
    "        stock_vec = sim_stock_mat[:, day + 1]\n",
    "        option_value = continuation_value\n",
    "\n",
    "        X_train = np.log(stock_vec)\n",
    "        X_train = X_train.reshape(-1, 5)\n",
    "        Y_train = option_value\n",
    "        Y_train = np.asarray(Y_train)\n",
    "        Y_train.reshape(-1, 1, 1)\n",
    "\n",
    "        nnet_output = model.fit(X_train, Y_train, epochs=no_of_epochs[day], batch_size=batch_size, verbose=0,\n",
    "                                validation_split=0.2, callbacks=[es])\n",
    "\n",
    "        w_vect = np.array(nnet_model.layers[0].get_weights()[0])\n",
    "        w_vect_2 = np.array(nnet_model.layers[1].get_weights()[0])\n",
    "        strikes = np.array(nnet_model.layers[0].get_weights()[1])\n",
    "        bias_2 = np.array(nnet_model.layers[1].get_weights()[1])\n",
    "        strikes = np.asarray(strikes)\n",
    "\n",
    "        stock_vec = sim_stock_mat[:, day]\n",
    "        x = np.log(stock_vec) + np.tile(((r - 0.5 * np.square(vol_list)) * dt).reshape(1, no_of_assets),\n",
    "                                        (no_of_paths, 1))\n",
    "        opt_val = np.zeros((no_of_paths, 1))\n",
    "\n",
    "        for node in range(0, no_of_hidden_nodes):\n",
    "            w_o = w_vect[:, node]\n",
    "            w_o = w_o.reshape(no_of_assets, 1)\n",
    "            mu = np.dot(x, w_o) + strikes[node]\n",
    "            var = np.dot(np.dot(w_o.T, cov_mat), w_o)\n",
    "            sd = var ** 0.5\n",
    "            ft = mu * (1 - norm(0, sd).cdf(-mu))\n",
    "            st = (sd / (2 * math.pi) ** 0.5) * np.exp(-0.5 * (mu / sd) ** 2)\n",
    "            opt_val = opt_val + w_vect_2[node] * (ft + st)\n",
    "\n",
    "        continuation_value = (opt_val + bias_2) * np.exp(-r * dt)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def pricer_bermudan_options_by_nn(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets, w, sim_stock_mat,\n",
    "                                  batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, model):\n",
    "    # Creating zero n-d arrays for intrinsic value, continuation value and option value\n",
    "    continuation_value = np.zeros((no_of_paths, 1))\n",
    "    stock_vec = sim_stock_mat[:, no_of_exercise_days]\n",
    "    intrinsic_value = np.maximum(k - np.dot(stock_vec, w), 0)\n",
    "    continuation_value = intrinsic_value\n",
    "    \n",
    "    for day in range(no_of_exercise_days - 1, -1, -1):\n",
    "        stock_vec = sim_stock_mat[:, day + 1]\n",
    "        \n",
    "\n",
    "        option_value = continuation_value\n",
    "\n",
    "        X_train = np.log(stock_vec)\n",
    "        X_train = X_train.reshape(-1, 5)\n",
    "        Y_train = option_value\n",
    "        Y_train = np.asarray(Y_train)\n",
    "        Y_train.reshape(-1, 1, 1)\n",
    "\n",
    "        nnet_output = model.fit(X_train, Y_train, epochs=no_of_epochs[day], batch_size=batch_size, verbose=1,\n",
    "                                validation_split=0.2, callbacks=[es])\n",
    "\n",
    "        w1 = nnet_model.layers[0].get_weights()\n",
    "        w2 = nnet_model.layers[1].get_weights()\n",
    "        w_dict[day] = ([w1, w2])\n",
    "        w_vect = np.array(nnet_model.layers[0].get_weights()[0])\n",
    "        w_vect_2 = np.array(nnet_model.layers[1].get_weights()[0])\n",
    "        strikes = np.array(nnet_model.layers[0].get_weights()[1])\n",
    "        bias_2 = np.array(nnet_model.layers[1].get_weights()[1])\n",
    "        strikes = np.asarray(strikes)\n",
    "        weights_dict[day] = ([nnet_model.layers[0].get_weights()[0], nnet_model.layers[1].get_weights()[0],\n",
    "                              nnet_model.layers[0].get_weights()[1], nnet_model.layers[1].get_weights()[1]])\n",
    "        stock_vec = sim_stock_mat[:, day]\n",
    "        x = np.log(stock_vec) + np.tile(((r - 0.5 * np.square(vol_list)) * dt).reshape(1, no_of_assets),\n",
    "                                        (no_of_paths, 1))\n",
    "        opt_val = np.zeros((no_of_paths, 1))\n",
    "\n",
    "        for node in range(0, no_of_hidden_nodes):\n",
    "            w_o = w_vect[:, node]\n",
    "            w_o = w_o.reshape(no_of_assets, 1)\n",
    "            mu = np.dot(x, w_o) + strikes[node]\n",
    "            var = np.dot(np.dot(w_o.T, cov_mat), w_o)\n",
    "            sd = var ** 0.5\n",
    "            ft = mu * (1 - norm(0, sd).cdf(-mu))\n",
    "            st = (sd / (2 * math.pi) ** 0.5) * np.exp(-0.5 * (mu / sd) ** 2)\n",
    "            opt_val = opt_val + w_vect_2[node] * (ft + st)\n",
    "\n",
    "        continuation_value = (opt_val + bias_2) * np.exp(-r * dt)\n",
    "\n",
    "    return (np.mean(continuation_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40dde0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16012/4091358938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Given Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mno_of_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mno_of_hidden_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# value = float(sys.argv[3])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "# Given Data\n",
    "no_of_paths = int(sys.argv[1])\n",
    "no_of_hidden_nodes = int(sys.argv[2])\n",
    "# value = float(sys.argv[3])\n",
    "value = 1\n",
    "\n",
    "w_dict = {}\n",
    "no_of_output_nodes = 1\n",
    "weights_dict = {}\n",
    "no_of_assets = 5\n",
    "\n",
    "# cor_mat = [[1.0, 0.79, 0.82, 0.91, 0.84],\n",
    "#            [0.79, 1.0, 0.73, 0.80, 0.76],\n",
    "#            [0.82, 0.73, 1.0, 0.77, 0.72],\n",
    "#            [0.91, 0.80, 0.77, 1.0, 0.90],\n",
    "#            [0.84, 0.76, 0.72, 0.90, 1.0]]\n",
    "\n",
    "cor_mat = [[1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "           [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "           [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "           [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "           [1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "\n",
    "vol_list = np.array([0.518, 0.648, 0.623, 0.570, 0.530])\n",
    "Notional = 100\n",
    "curr_stock_price = np.ones(no_of_assets) * value\n",
    "t = 1\n",
    "k = 1\n",
    "no_of_exercise_days = 1\n",
    "r = 0.05\n",
    "w = np.array([0.381, 0.065, 0.057, 0.270, 0.227])\n",
    "w = w.reshape(-1, 1)\n",
    "exercise_days = np.array([float(i / no_of_exercise_days) for i in range(1, no_of_exercise_days + 1)])\n",
    "dt = t / no_of_exercise_days\n",
    "\n",
    "# Generate covariance matrix without considering dt\n",
    "cov_mat = generate_covariance_from_correlation(cor_mat, vol_list, dt)\n",
    "\n",
    "price_list = []\n",
    "for i in range(0, 30):\n",
    "    \n",
    "    sim_stock_mat = multi_variate_gbm_simulation(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets,\n",
    "                                                 curr_stock_price, r, vol_list, cov_mat, t)\n",
    "    batch_size = int(no_of_paths / 10)\n",
    "    no_of_epochs = np.array([100, 100, 100, 500, 500, 500, 500, 2000])\n",
    "\n",
    "    nnet_model = Sequential()\n",
    "    nnet_model.add(Dense(no_of_hidden_nodes, activation='relu', kernel_initializer='random_uniform'))\n",
    "    nnet_model.add(Dense(1, activation='linear', kernel_initializer='normal'))\n",
    "    nnet_model.compile(optimizer=opt.Adam(lr=0.001), loss='mean_squared_error')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "    nnet_model = pricer_arithmetic_pre(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets, w, sim_stock_mat,\n",
    "                                       batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model)\n",
    "    K.set_value(nnet_model.optimizer.lr, 5e-4)\n",
    "\n",
    "    sim_stock_mat = multi_variate_gbm_simulation(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets,\n",
    "                                                 curr_stock_price, r, vol_list, cov_mat, t)\n",
    "\n",
    "    nnet_model = pricer_arithmetic_pre(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets, w, sim_stock_mat,\n",
    "                                      batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model)\n",
    "\n",
    "    K.set_value(nnet_model.optimizer.lr, 1e-3)\n",
    "\n",
    "    price = pricer_bermudan_options_by_nn(no_of_paths, no_of_exercise_days, exercise_days, no_of_assets, w, sim_stock_mat,\n",
    "                                          batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model)\n",
    "\n",
    "    price_list.append(price)\n",
    "    \n",
    "df = pd.DataFrame({'Runs:' + str(no_of_paths):price_list})\n",
    "# df.to_csv('df_pv_comonotonic_nn_nodes_' + str(no_of_hidden_nodes) + '_sim' + str(no_of_paths) + '.csv')\n",
    "print(df)\n",
    "# text_file = open('European_Arithmetic.txt', \"a\")\n",
    "# strx = \"\\n Paths: \"+ str(no_of_paths)+\", Nodes: \"+str(no_of_hidden_nodes)+\", Price: \" + str(price*Notional)\n",
    "# text_file.write(strx)\n",
    "# text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012d533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
